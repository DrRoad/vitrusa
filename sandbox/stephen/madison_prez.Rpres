
Digital summaries of legacy pedon descriptions
========================================================
author: Stephen Roecker, Dylan Beaudette, Jay Skovlin, Skye Wills
date: 6/1/2015


Legacy pedon data within the US
========================================================

```{r, echo=FALSE}
library(ggplot2)
library(knitr)

pedons <- c(577, 6152, 9517, 19058, 42587, 112182, 231609, 184913)
year <- c("<1950s", "1950s", "1960s", "1970s", "1980s", "1990s", "2000s", "2010s")

cat("# pedons = ", formatC(sum(pedons), big.mark = ",", format = "fg"), "\n", "# lab pedons = ~64,000", sep = "")

ggplot(data.frame(pedons, year), aes(x=year, y=pedons)) + geom_bar(stat="identity")

# There has been lots of talk about the number or Soil Series, Components, Map units, etc... but little focus on the point data resource.

```

```{r Henry comments, echo=FALSE}
# [5/14/2015 9:03 AM] Ferguson, Henry - NRCS, Lincoln, NE: 
# That is a tough one
# [5/14/2015 9:03 AM] Ferguson, Henry - NRCS, Lincoln, NE: 
# Take 600,000 and subtract about 20 percent for duplicates
# [5/14/2015 9:03 AM] Ferguson, Henry - NRCS, Lincoln, NE: 
# You might subtract another 5 or 10 percent for pace holders of data.

# [5/14/2015 9:04 AM] Ferguson, Henry - NRCS, Lincoln, NE: 
#And there are lots of notes, so the total number of full pedon descriptions is probably between 300 and 350,000
# [5/14/2015 9:04 AM] Ferguson, Henry - NRCS, Lincoln, NE: 
# There are about 64,000 pedons with laboratory data (no duplicates counted)

# [5/14/2015 10:04 AM] Ferguson, Henry - NRCS, Lincoln, NE: 
# It is not so much that there were more pedons described as the fact that they were easier to input
# [5/14/2015 10:04 AM] Ferguson, Henry - NRCS, Lincoln, NE: 
# Pedon PC was developed in about 2005 and we got personal computers in about 1995
# [5/14/2015 10:05 AM] Ferguson, Henry - NRCS, Lincoln, NE: 
# So folks started to put the pedons in databases in the 1990's and then we imported them in the 2000's
# [5/14/2015 10:05 AM] Ferguson, Henry - NRCS, Lincoln, NE: 
# There also was a midset change from putting just select pedons into the database to collecting all point data in the database
```


NRCS soil databases
========================================================

1. National Soil Information System (NASIS) (SQL Server)
   * SSURGO and Soil Data Access
   * STASTGO2
2. Soil Characterization Database (Access)
3. Ecological Site Descriptions (Text)
4. Official Series Descriptions (Text)

_* sorted by database sophistication_


NASIS
========================================================
![alt text](figures/nasis.png)

```{r nasis comments, echo=FALSE}
# Illustrate child tables
# Discuss MS SQL Server
# Point data vs. aggregate data
# "The original digital soil morphometrics"
```

* Analysis is limited to a subset of SQL functions
* 99% of existing reports are for aggregate data
* No inherent graphing capability


Tools for interacting with soil data
========================================================
### Tabular analysis

    1. Pen and paper
    2. Excel
    3. PedonPC and AnalysisPC (Access front ends) 
    4. NASIS
    5. R

### Spatial analysis
    1. SoilWeb
    2. Web Soil Survey
    3. Soil Data Viewer
    4. SSURGO file geodatabases
    5. R
    
_* sorted by user sophistication_

```{r tool comments, echo=FALSE}
# Typical data is exported to Access or Excel for analysis.
```


Objective?
========================================================
### Problems
    1. Data is underutilized
    2. Inefficient tools
    3. R is hard

### Solution
    1. standardized R reports

```{r, echo=FALSE}
cat("")
```

What do we need?
=======================================================

```{r need comments, echo=FALSE}
# The data elements used in the NRCS databases are well defined, thus we simply need some why of summarizing it quickly.


```


Aggregation of Pedon Data: Common Problems
========================================================
![alt text](static-figures/genhz-sketch.png)

- description styles
 - the age-old splitters vs. lumpers
 - use of transitional horizons - I say tomato, you say tomato!
  
- legacy horizon nomenclature
 - old school meets new school and they ain't speakin' the same language.....

- soils described to varying depths - it's the pits!


Generalized Horizon Labels: Micro-correlation
========================================================
![alt text](static-figures/genhz-sketch.png)

- generalized horizon labels = GHL
- determine the core concept 
- which way do transition horizons go?
 - GHL process allows for flexibility
- horizon redundancy - how many Bt horizons are necessary?
- outlier horizons - what happens to them?


Summary of GHL workflow
========================================================

<center>**Most of these steps are implemented in the reports presented last**</center>

1. Select a set of GHL that best represents a group of pedons to be aggregated.

2. Assign GHL to each horizon using whatever information is available for grouping horizons.

3. Evaluate GHL assignments and manually refine as needed.

4. Keep track of final GHL assignments in NASIS or text file.

5. Estimate a most likely horizonation e.g., top and bottom depths for each generalized horizon label.

6. Compute range in characteristics, aka low-rv-high values, for clay, sand, pH, etc. over GHL. (next document in this series)

[&#8594;&nbsp;extended tutorial](https://r-forge.r-project.org/scm/viewvc.php/*checkout*/docs/aqp/gen-hz-assignment.html?root=aqp)



Assumptions
========================================================
- a collection of pedons for a component should represent an aggregated component
- a GHL process of some kind is required to efficiently summarize and aggregate horizon data from these collections
- low-rv-high values must be tied to some metric: 
 - 5th-50th-95th percentile is one option
- linked pedons represent examples of the aggregate data, but aggregate data should not be limited to a very small set of linked pedons

- **IMPORTANT** these reports and data summaries are a useful *starting point* for the aggregation process




Summarizing Data with Quantiles (Percentiles)
========================================================

- suggested basis for RIC: 
  - 5th, 50th, and 95th percentiles are low-rv-high values
  - no assumptions of distribution, simple interpretation

```{r quantiles-normal-dist, fig.width=11, fig.height=6, echo=FALSE}
# simulate 500 values from the normal distribution: with mean = 10, sd= 2
set.seed(1010101)
x <- rnorm(n=500, mean = 10, sd=2)

# compute the 5th, 25th, 50th, 75th, and 95th percentiles of x
q <- c(quantile(x, probs=c(0.05, 0.25, 0.5, 0.75, 0.95)))

# plot a smoothed frequency distribution
plot(density(x), main=list('Normal Distibution', cex=2), ylim=c(0, 0.8), ylab='', xlab='', axes=FALSE)

# mark quantiles we computed above
abline(v=q, lty=3, col='red')
text(x=q, y=0.1, labels=c('5th', '25th', '50th', '75th', '95th'), cex=1.5)

# overlay a box-whisker plot
boxplot(x, at=0.35, add=TRUE, horizontal=TRUE, boxwex=0.1, border='DarkBlue', axes=FALSE)

# overlay lines at the original values
rug(x, side=3, col='DarkBlue')

# overlay mean +/- 2SD
points(mean(x), y=0.45, pch=0, col='darkgreen', cex=2, lwd=2)
points(mean(x) + c(2*sd(x), -2*sd(x)), y=c(0.45, 0.45), pch=0, col='darkgreen', cex=2, lwd=2)

# add x-axis
axis(side=1, at=pretty(x), cex.axis=1.5)
```


Summarizing Data with Quantiles (Percentiles)
========================================================

- suggested basis for RIC: 
  - 5th, 50th, and 95th percentiles are low-rv-high values
  - no assumptions of distribution, simple interpretation

```{r quantiles-exp-dist, fig.width=11, fig.height=6, echo=FALSE}
# simulate 500 values from the exponential distribution
set.seed(1010101)
x <- rexp(n=500)

# compute the 5th, 25th, 50th, 75th, and 95th percentiles of x
q <- c(quantile(x, probs=c(0.05, 0.25, 0.5, 0.75, 0.95)))

# plot a smoothed frequency distribution
plot(density(x), main=list('Long-Tailed Distibution', cex=2), xlim=c(-1, 8), ylim=c(0, 0.8), ylab='', xlab='', axes=FALSE)

# mark quantiles we computed above
abline(v=q, lty=3, col='red')
text(x=q, y=c(0.1, 0.15, 0.1, 0.15, 0.1), labels=c('5th', '25th', '50th', '75th', '95th'), cex=1.5)

# overlay a box-whisker plot
boxplot(x, at=0.35, add=TRUE, horizontal=TRUE, boxwex=0.1, border='DarkBlue', axes=FALSE)

# overlay lines at the original values
rug(x, side=3, col='DarkBlue')

# overlay mean +/- 2SD
points(mean(x), y=0.45, pch=0, col='darkgreen', cex=2, lwd=2)
points(mean(x) + c(2*sd(x), -2*sd(x)), y=c(0.45, 0.45), pch=0, col='darkgreen', cex=2, lwd=2)

# add x-axis
axis(side=1, at=pretty(x), cex.axis=1.5)
```


A Sample Dataset
=======================================================

- 15 pedons correlated to the [Loafercreek](https://soilseries.sc.egov.usda.gov/OSD_Docs/L/LOAFERCREEK.html) soil series
- Fine-loamy, mixed, superactive, thermic Ultic Haploxeralfs
- Common soil formed on meta-volcanic rocks of the Sierra Nevada Foothills, MLRA 18
- Included in the `soilDB` package for testing purposes

```{r load-data, fig.width=12, fig.height=5, echo=FALSE}
# load sample data from the soilDB package
data(loafercreek, package = 'soilDB')

# keep only the first 15 pedons
pedons <- loafercreek[1:15, ]

# plot profile sketches
par(mar=c(0,0,0,0))
plot(pedons, name='hzname', print.id=FALSE, cex.names=0.8, axis.line.offset=-4)
```

Consult the OSD for Ideas
========================================================
- Look up the series RIC if available

![alt text](static-figures/RIC.png)

- Horizons from the OSD may be a good starting point for GHL template



Tabulate Horizon Designations
========================================================

- sort by frequency
```{r sort-hz-by-freq-print-html, echo=FALSE, results='asis'}
d <- sort(table(pedons$hzname), decreasing=TRUE)
d <- t(d)
kable(as.data.frame.matrix(d))
```

- sort alphabetically
```{r sort-hz-by-alph-print-html, echo=FALSE, results='asis'}
d <- table(pedons$hzname)
d <- t(d)
kable(as.data.frame.matrix(d))
```

- plot ranges in horizon depths
```{r horizonation-mid-point, echo=FALSE, fig.width=10, fig.height=4}
# compute horizon mid-points
pedons$mid <- with(horizons(pedons), (hzdept + hzdepb) / 2)

# sort horizon designation by group-wise median values
hz.designation.by.median.depths <- names(sort(tapply(pedons$mid, pedons$hzname, median)))

# plot the distribution of horizon mid-points by designation
bwplot(mid ~ factor(hzname, levels=hz.designation.by.median.depths), 
       data=horizons(pedons), 
       ylim=c(155, -5), ylab='Horizon Mid-Point Depth (cm)', 
       scales=list(y=list(tick.number=10)), 
       panel=function(...) {
  panel.abline(h=seq(0, 140, by=10), v=1:length(hz.designation.by.median.depths), col=grey(0.8), lty=3)
  panel.bwplot(...)
})
```


Summarize Available Soil Properties
========================================================


```{r univariate-eval-clay, echo=FALSE, fig.width=10, fig.height=4}
bwplot(clay ~ factor(hzname, levels=hz.designation.by.median.depths), 
       data=horizons(pedons), 
       ylab='Clay Content (%)', 
       scales=list(y=list(tick.number=10)), 
       panel=function(...) {
  panel.abline(h=seq(0, 100, by=5), v=1:length(hz.designation.by.median.depths), col=grey(0.8), lty=3)
  panel.bwplot(...)
})
```

```{r univariate-eval-rf, echo=FALSE, fig.width=10, fig.height=4}
# box and wisker plot by total rock fragment volume
bwplot(total_frags_pct ~ factor(hzname, levels=hz.designation.by.median.depths), 
       data=horizons(pedons), 
       ylab='Total Rock Fragment Volume (%)', 
       scales=list(y=list(tick.number=10)), 
       panel=function(...) {
  panel.abline(h=seq(0, 100, by=10), v=1:length(hz.designation.by.median.depths), col=grey(0.8), lty=3)
  panel.bwplot(...)
})
```


Determination of a GHL Template and Rules
========================================================
- pattern matching via [regular expression](http://www.regexr.com/) (REGEX)
 - this is where most micro-correlation decisions are defined

- GHL and rules for our sample dataset:
  - **A**: `^A$|Ad|Ap`
  - **Bt1**: `Bt1$`
  - **Bt2**: `^Bt2$`
  - **Bt3**: `^Bt3|^Bt4|CBt$|BCt$|2Bt|2CB$|^C$`
  - **Cr**: `Cr`
  - **R**: `R`

- special characters in REGEX rules: 
 - `|` = "or"
 - `^` = anchor to left-side
 - `$` = anchor to right-side

```{r ghl-regex-rules, echo=FALSE}
# GHL
n <- c('A', 
       'Bt1',
       'Bt2',
       'Bt3',
       'Cr',
       'R')
# REGEX rules
p <- c('^A$|Ad|Ap',
       'Bt1$',
       '^Bt2$',
       '^Bt3|^Bt4|CBt$|BCt$|2Bt|2CB$|^C$',
       'Cr',
       'R')
```

Assignment of GHL
========================================================

- cross-tabulation of original names (columns) vs. GHL (rows)
- be sure to check the `not-used` row

```{r assign-ghl-print-table, results='asis', echo=FALSE}
pedons$genhz <- generalize.hz(pedons$hzname, n, p) 
# cross-tabulate original horizon designations and GHL
kable(addmargins(table(pedons$genhz, pedons$hzname)))
```



Evaluation of GHL
========================================================

- plot profiles with horizons colored according to GHL
- does it make sense?
- what about horizons in the `not-used` group?

```{r plot-ghl-1, echo=FALSE, fig.width=12, fig.height=5, htmlcap='Horizon colors are based on assigned GHL.'}
# make a palette of colors, last color is for not-used class
cols <- c(grey(0.33), 'orange', 'orangered', 'chocolate', 'green', 'blue', 'yellow')
# assign a color to each generalized horizon label
hz.names <- levels(pedons$genhz)
pedons$genhz.soil_color <- cols[match(pedons$genhz, hz.names)]
# plot generalized horizons via color and add a legend
par(mar=c(4,0,0,0))
plot(pedons, name='hzname', print.id=FALSE, cex.names=0.8, axis.line.offset=-4, color='genhz.soil_color')
legend('bottomleft', legend=hz.names, pt.bg=c(cols), pch=22, bty='n', cex=2)
```



Importing GHL to NASIS
========================================================
- generalized horizon labels (so far) are stored in R session
- Use an R script to create a text file, called `horizon_agg.txt`, of horizon ID's and corresponding GHL assignments
- run the NASIS calculation to update the comp layer id field with the GHL for each pedon horizon
- Calculations/Validations --> Pedon Horizon 
  - 'Update horizon group aggregations using a text file'
  - Calculation will look for the `horizon_agg.txt file` in: `C:/data/horizon_agg.txt`
  - Calculation will load the file and update the comp layer id field
- manual adjustments in NASIS: outliers, special cases, etc.

[&#8594;&nbsp;full instructions here](https://r-forge.r-project.org/scm/viewvc.php/*checkout*/docs/aqp/gen-hz-assignment.html?root=aqp)




Demonstration of Several Report Styles
========================================================

- Stephen's Examples: 
  - [Lecyr Pedon Report](https://github.com/sroecker01/soil-pit/blob/master/examples/lecyr_pedon_report.md)
  - [Genesee Lab Data Report](https://github.com/sroecker01/soil-pit/blob/master/examples/genesee_lab_report.md)
  - [Cincinanti Map Unit Report](https://github.com/sroecker01/soil-pit/blob/master/examples/cincinnati_mapunit_report.md)

- Dylan's Examples:
  - [Loafercreek Pedon Report](https://r-forge.r-project.org/scm/viewvc.php/*checkout*/docs/example-reports/loafercreek.html?root=aqp)
  - [Dunstone Pedon Report](https://r-forge.r-project.org/scm/viewvc.php/*checkout*/docs/example-reports/dunstone.html?root=aqp)
  - [Amador Pedon Report](https://r-forge.r-project.org/scm/viewvc.php/*checkout*/docs/example-reports/amador.html?root=aqp)


Questions and thoughts ?
========================================================
**How many Professors here teach a course in Data Analysis?**

**If not, why not?**

**Soil scientists are great at collecting data, but we have to just as good at analyzing it.**


Thank You
========================================================
**Questions, comments, ideas**
<br><br>

**R resources for pedologists**
- <span class="link-to-details">&#8594;&nbsp;[NCSS Job-Aids](http://www.nrcs.usda.gov/wps/portal/nrcs/detail/soils/edu/ncss/?cid=nrcs142p2_054322)</span>
- <span class="link-to-details">&#8594;&nbsp;[aqp tutorials](http://aqp.r-forge.r-project.org/)</span>
- <span class="link-to-details">&#8594;&nbsp;[Statistical data analysis for pedologists](http://www2.gru.wvu.edu/~tdavello/files/stats/table_of_contents.html)
- <span class="link-to-details">&#8594;&nbsp;[Dylan Beaudette's blog](http://casoilresource.lawr.ucdavis.edu/blog/)
- <span class="link-to-details">&#8594;&nbsp;[soil-pit Github repository](https://github.com/sroecker01/soil-pit)
<br><br>

**Additional AQP Contributors:**
- Pierre Roudier (Landcare Research)